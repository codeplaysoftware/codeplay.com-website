---
id: 162
url: codeplay-is-attending-the-2015-llvm-developers-meeting
user_id: 335
date: 2015-10-27T18:22:42.3600Z
category: news
title: "Codeplay is attending the 2015 LLVM Developers' Meeting"
showOnFrontPage: 0
views: 0
tags:
redirect_from:
  - /portal/codeplay-is-attending-the-2015-llvm-developers-meeting
layout: portal/portal-article-view
thumbnail: /assets/images/portal/no-thumbnail-placeholder.png
---

<p>Codeplay will be attending the <a href="http://llvm.org/devmtg/2015-10/index.html">2015 LLVM Developers' Meeting</a>, 29-30 October in San Jose, US.
</p>
<p>
This year the conference will be 2 full days that include technical talks, BoFs, hacker’s lab, tutorials, and a poster session.
</p>
<p>
The meeting serves as a forum for LLVM, Clang, LLDB and other LLVM project developers and users to get acquainted, learn how LLVM is used, and exchange ideas about LLVM and its (potential) applications. More broadly, we believe the event will be of particular interest to the following people:
</p><ul>
<li> Active developers of projects in the LLVM Umbrella (LLVM core, Clang, LLDB, libc++, compiler_rt, klee, dragonegg, lld, etc).</li>
<li> Anyone interested in using these as part of another project.</li>
<li> Compiler, programming language, and runtime enthusiasts.</li>
<li> Those interested in using compiler and toolchain technology in novel and interesting ways.</li>
</ul>



<p>
Three of our own engineers will be attending: Pierre-Andre Saulais, Verena Beckham, and Ewan Crawford.
</p>
<p>
On Thursday at 3pm Pierre-Andre will be giving a talk entitled, &quot;Creating an SPMD Vectorizer for OpenCL with LLVM&quot;:
</p>
<p>
<em>Processors such as CPUs or DSPs often feature SIMD instructions, but are not designed to efficiently support Single Program Multiple Data (SPMD) execution models such as OpenCL. The design of a compiler for such a target therefore needs some form of vectorization to generate the most optimal code for this kind of data-parallel execution model. This is because SPMD programs are most often written in scalar form with the implicit assumption that many instances of the program are executed in parallel. On CPU-like architectures, SIMD vector units can be leveraged for parallelism, such that each SIMD lane is loosely mapped to a program instance. </em><em> </em></p>
<p>
<em>This tutorial looks at how to create an SPMD vectorizer that targets CPU-like architectures for use with heterogeneous compute frameworks. OpenCL is used as an example but the concepts should translate to other frameworks such as CUDA, RenderScript or Vulkan Compute. While there are other possible approaches, we have chosen to present one that works at the LLVM IR level and that is essentially an IR pass that creates vectorized functions from the original scalar SPMD function. This allows targetting multiple architectures with very little architecture-specific code. </em><em> </em></p>
<p>
<em>We will start by briefly introducing the SPMD execution model, describing how it is used in OpenCL and giving an overview of what a SPMD vectorizer should do and how it differs from other kinds such as LLVM's loop vectorizer and SLP vectorizer. Then we will look at a possible vectorizer design, including the different vectorization stages (analysis, control-flow to data-flow, scalarization, packetization/instantiation and optimization/cleanup). Finally, we will look at some possible optimizations as well as other aspects that do not fit the 'stage-by-stage' presentation (e.g. vectorizing and scalarizing calls to builtin functions, SIMD width detection, interleaved memory access optimizations, SoA to AoS conversions, etc). </em><em> </em></p>
<p>
We’re always delighted to speak with anyone interested in what we’re doing, so please come and say “hello”. If you would like to arrange a meeting with us at the event, please follow us on <a href="http://www.twitter.com/codeplaysoft">@codeplaysoft</a> and make contact!</p>

