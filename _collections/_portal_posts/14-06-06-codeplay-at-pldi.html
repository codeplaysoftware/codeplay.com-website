---
id: 100
url: codeplay-at-pldi
user_id: 368
date: 2014-06-06T18:43:02.7200Z
category: news
title: "Codeplay at PLDI"
showOnFrontPage: 0
views: 192
tags: PLDI
redirect_from:
  - /portal/codeplay-at-pldi
layout: portal/portal-article-view
thumbnail: /assets/images/portal/no-thumbnail-placeholder.png
---

<p>Paul Keir, Ruyman Reyes, and JinGu Kang of Codeplay will attend next week's <a href="http://conferences.inf.ed.ac.uk/pldi2014/">PLDI 2014</a> - the 35th annual ACM SIGPLAN conference on Programming Language Design and Implementation. PLDI is a forum where researchers, developers, educators, and practitioners exchange information on the latest practical and experimental work in the design and implementation of programming languages. This year's PLDI will be held in the <a href="http://www.assemblyroomsedinburgh.co.uk/">Assembly Rooms</a> in Edinburgh.
</p>
<p>
There are two co-located events (<a href="http://www.ittc.ku.edu/lctes14">LCTES</a> and <a href="http://ismm2014.cs.tufts.edu">ISMM</a>
ISMM), eight workshops, and seven tutorials this year. Of the workshops, Codeplay's head of R&amp;D, Paul Keir, has the pleasure of delivering the keynote speech for the <a href="http://mspcworkshop.org">MSPC</a> workshop. The abstract for his talk is below:
</p>
<p>
<strong>Memory Hierarchy Visibility in Parallel Programming Languages</strong>
</p>
<p>
<em>The choice as to which levels in a memory hierarchy are exposed within a programming language or API can be critical. Expose too many, and you risk programmability, and performance portability.</em></p>
<p>
Heterogeneous computing and GPGPU aims to repurpose the data-parallel capability of graphics and commodity hardware for general calculations. GPGPU APIs, which now include OpenCL SYCL; Apple's Metal; and Qualcomm's MARE; must all decide on a suitable abstraction for hardware memory levels. Established GPGPU APIs such as CUDA, C++AMP, and OpenCL offer language support for four levels of volatile memory. However, while the presence of GPUs are now essentially ubiquitous, the diminished role of discrete graphics cards invigorates questions regarding memory abstraction.
</p>
<p>
The multicore revolutionaries have now ceded mobile computing to the CPU-GPU system-on-chips; firmly established in mainstream options such as the Qualcomm Snapdragon; Samsung Exynos; and the AMD APU series. Meanwhile, the HSA Foundation builds upon a bedrock of uniform memory access; the Android GPGPU API, Renderscript, eschews explicit memory address spaces; and CUDA now offers &quot;unified&quot; memory. Can cach√© once again mean hidden?
<em> </em></p>

